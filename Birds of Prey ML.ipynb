{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319269e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e167732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"/Users/olivianystrom/Desktop/Springboard/CA_Birds_of_Prey/Birds_of_Prey_ML.csv\")\n",
    "df = pd.read_csv(\"/Users/olivianystrom/Desktop/Springboard/CA_Birds_of_Prey/Birds_of_Prey_ML.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471e4deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4239061, 29)\n",
      "   Unnamed: 0        COMMON NAME           SCIENTIFIC NAME OBSERVATION DATE  \\\n",
      "0           0         Bald Eagle  Haliaeetus leucocephalus       1999-01-18   \n",
      "1           1      Cooper's Hawk        Accipiter cooperii       1996-10-13   \n",
      "2           2    Red-tailed Hawk         Buteo jamaicensis       1997-08-22   \n",
      "3           3   American Kestrel          Falco sparverius       1995-09-11   \n",
      "4           4  White-tailed Kite           Elanus leucurus       1994-10-15   \n",
      "\n",
      "                     Size  Brown  White  Gray  Orange  Black  ... robin-sized  \\\n",
      "0   goose-sized or larger      1      1     0       0      0  ...           0   \n",
      "1              crow-sized      0      0     1       1      0  ...           0   \n",
      "2  between crow and goose      1      1     0       1      0  ...           0   \n",
      "3             robin-sized      0      0     1       1      1  ...           1   \n",
      "4  between crow and goose      0      1     1       0      1  ...           0   \n",
      "\n",
      "  between robin and crow  crow-sized  between crow and goose  \\\n",
      "0                      0           0                       0   \n",
      "1                      0           1                       0   \n",
      "2                      0           0                       1   \n",
      "3                      0           0                       0   \n",
      "4                      0           0                       1   \n",
      "\n",
      "   goose-sized or larger  Lat_normalized  Long_normalized  COMMON NAME_cat  \\\n",
      "0                      1        0.974463         0.171715                1   \n",
      "1                      0        0.138719         0.758075                6   \n",
      "2                      0        0.131762         0.848168               20   \n",
      "3                      0        0.350562         0.661289                0   \n",
      "4                      0        0.473572         0.383178               26   \n",
      "\n",
      "   Size_cat  Birdtype_cat  \n",
      "0         4             0  \n",
      "1         3             2  \n",
      "2         0             2  \n",
      "3         5             3  \n",
      "4         0             4  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f613e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and train data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Brown', 'White',\n",
    "       'Gray', 'Orange', 'Black','between sparrow and robin', 'robin-sized',\n",
    "       'between robin and crow', 'crow-sized', 'between crow and goose', 'Lat_normalized', \n",
    "       'Long_normalized']], df[['Hawk', 'Falcon', 'Kite', 'Eagle','Owl']], \n",
    "       test_size=0.33, random_state=42)\n",
    "\n",
    "X_train_name, X_test_name, y_train_name, y_test_name = train_test_split(df[['Brown', 'White',\n",
    "       'Gray', 'Orange', 'Black','between sparrow and robin', 'robin-sized',\n",
    "       'between robin and crow', 'crow-sized', 'between crow and goose', 'Lat_normalized', \n",
    "       'Long_normalized']], df['COMMON NAME_cat'], \n",
    "       test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5287021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2840170, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ddc2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small = X_train.head(500000)\n",
    "y_train_small = y_train.head(500000)\n",
    "\n",
    "X_train_name_small = X_train_name.head(500000)\n",
    "y_train_name_small = y_train_name.head(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758681e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy=0.951\n",
      "Random Forest: f1-score=0.941\n"
     ]
    }
   ],
   "source": [
    "#starting with the random forest model, only classifying into Category (hawk/kestrel/falcon/etc)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state = 1,n_jobs=-1)\n",
    "model_res = clf.fit(X_train, y_train)\n",
    "y_pred = model_res.predict(X_test)\n",
    "y_pred_prob = model_res.predict_proba(X_test)\n",
    "\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Random Forest: Accuracy=%.3f' % (ac))\n",
    "\n",
    "print('Random Forest: f1-score=%.3f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3cc2809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy=0.824\n",
      "Random Forest: f1-score=0.815\n"
     ]
    }
   ],
   "source": [
    "#Still random forest, this time predicting species \n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state = 1,n_jobs=-1)\n",
    "model_res_name = clf.fit(X_train_name, y_train_name)\n",
    "y_pred_name = model_res_name.predict(X_test_name)\n",
    "y_pred_prob_name = model_res_name.predict_proba(X_test_name)\n",
    "\n",
    "ac_name = accuracy_score(y_test_name, y_pred_name)\n",
    "\n",
    "f1_name = f1_score(y_test_name, y_pred_name, average='weighted')\n",
    "\n",
    "print('Random Forest: Accuracy=%.3f' % (ac_name))\n",
    "\n",
    "print('Random Forest: f1-score=%.3f' % (f1_name))\n",
    "\n",
    "#Species result is actually fairly accurate, will continue to Classify by species moving forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d04203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olivianystrom/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:17:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost: Accuracy=0.817\n",
      "XGBoost: f1-score=0.797\n"
     ]
    }
   ],
   "source": [
    "#Using XGBoost Classifier, classifying by species and only using 500,000 lines of the train data because the code \n",
    "#took a long time to run. XGBoost is run with the full dataset in the next cell\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train_name_small, y_train_name_small)\n",
    "    \n",
    "y_pred_name = xgb_model.predict(X_test_name)\n",
    "# y_pred_name = pd.DataFrame(y_pred_name)\n",
    "\n",
    "ac_name = accuracy_score(y_test_name, y_pred_name)\n",
    "\n",
    "f1_name = f1_score(y_test_name, y_pred_name, average='weighted')\n",
    "\n",
    "print('XGBoost: Accuracy=%.3f' % (ac_name))\n",
    "\n",
    "print('XGBoost: f1-score=%.3f' % (f1_name))\n",
    "\n",
    "#Results are not as good as the Random Forest model but still comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3e51f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olivianystrom/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:21:21] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost: Accuracy=0.820\n",
      "XGBoost: f1-score=0.799\n"
     ]
    }
   ],
   "source": [
    "#XGBoost Classifier run to predict species with the full dataset\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train_name, y_train_name)\n",
    "    \n",
    "y_pred_name = xgb_model.predict(X_test_name)\n",
    "# y_pred_name = pd.DataFrame(y_pred_name)\n",
    "\n",
    "ac_name = accuracy_score(y_test_name, y_pred_name)\n",
    "\n",
    "f1_name = f1_score(y_test_name, y_pred_name, average='weighted')\n",
    "\n",
    "print('XGBoost: Accuracy=%.3f' % (ac_name))\n",
    "\n",
    "print('XGBoost: f1-score=%.3f' % (f1_name))\n",
    "\n",
    "#Accuracy and fl-score are better here, but not by much, and while comparable with the Random Forest model\n",
    "#The Random Forest model ran much more quickly. If we were to refine this, I would use the RF model and consider\n",
    "#chopping down the train code since we can significantly reduce the runtime of the code without much impact on \n",
    "#Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
